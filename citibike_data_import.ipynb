{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citibike Ridership Data Import\n",
    "\n",
    "This notebook performs initial data processing on Citibike ridership data to prepare it for time series analysis. There are two main steps:\n",
    "- Read in monthly ride level data, process it (aggregate it to daily data by station ID, drop columns), and concatenate\n",
    "- Append neighborhood and borough level information to each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point, Polygon, shape\n",
    "import geopandas as gpd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import util functions to pre-process the data\n",
    "\n",
    "from util.preprocess_util import pre_process, pre_process_2021, convert_station, get_neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborhood_json(point):\n",
    "    '''\n",
    "    Function accepts a Point object from the shapely library.\n",
    "    It parses through the JSON of nyc neighborhood geo data, checking if any of them contain the point.\n",
    "    If there is a match, the neighborhood name is returned.\n",
    "    \n",
    "    '''\n",
    "    for feature in nycmap['features']:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if polygon.contains(point):\n",
    "            return feature['properties']['ntaname']\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def borough_json(point):\n",
    "    '''\n",
    "    This is a repeat of the function above, except to return borough instead of neighborhood.\n",
    "    \n",
    "    Function accepts a Point object from the shapely library.\n",
    "    It parses through the JSON of nyc neighborhood geo data, checking if any of them contain the point.\n",
    "    If there is a match, the borough name is returned.\n",
    "    \n",
    "    '''\n",
    "    for feature in nycmap['features']:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if polygon.contains(point):\n",
    "            return feature['properties']['boro_name']\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and process initial ridership level data\n",
    "\n",
    "- The files are read in partitioned based on common file and column name structure\n",
    "    - June 2013 standalone\n",
    "    - July 2013 through August 2014\n",
    "    - Sept 2014 through Sept 2016\n",
    "    - Oct 2016 through March 2017 (pass in different column names)\n",
    "    - April 2017 through Jan 2021\n",
    "    - Feb 2021 through Oct 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time threshold to ensure there are no rides under 60 seconds\n",
    "\n",
    "time_threshold = timedelta(seconds=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard column names to be used throughout\n",
    "\n",
    "standard_cols = ['tripduration', 'starttime', 'stoptime', 'start station id', 'start station name', \n",
    "                 'start station latitude', 'start station longitude', 'end station id', 'end station name', \n",
    "                 'end station latitude', 'end station longitude', 'bikeid', 'usertype', 'birth year', 'gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in June 2013\n",
    "\n",
    "df_201306 = pd.read_csv('./ridership_raw/201306-citibike-tripdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess June 2013 dataset\n",
    "\n",
    "df_201306 = pre_process(df_201306)\n",
    "\n",
    "df_201306.to_csv('./processed/201306.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in July 2013 through August 2014\n",
    "\n",
    "# df_list1 = []\n",
    "\n",
    "month = 7\n",
    "year = 2013\n",
    "\n",
    "for i in range(14):\n",
    "    \n",
    "    if month > 12:\n",
    "        month = 1\n",
    "        year = 2014\n",
    "    \n",
    "    if month >= 10:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}-{month} - Citi Bike trip data.csv\")\n",
    "        df = pre_process(df)\n",
    "        df.to_csv(f\"./processed/{year}{month}.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}-0{month} - Citi Bike trip data.csv\")\n",
    "        df = pre_process(df)\n",
    "        df.to_csv(f\"./processed/{year}0{month}.csv\")\n",
    "    \n",
    "    month += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Sept 2014 through Sept 2016\n",
    "\n",
    "# df_list2 = []\n",
    "\n",
    "month = 9\n",
    "year = 2014\n",
    "\n",
    "for i in range(25):\n",
    "    \n",
    "    if month > 12:\n",
    "        month = 1\n",
    "        year += 1\n",
    "    \n",
    "    if month >= 10:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}{month}-citibike-tripdata.csv\")\n",
    "        df = pre_process(df)\n",
    "        df.to_csv(f\"./processed/{year}{month}.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}0{month}-citibike-tripdata.csv\")\n",
    "        df = pre_process(df)\n",
    "        df.to_csv(f\"./processed/{year}0{month}.csv\")\n",
    "    month += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9748 entries, 0 to 9747\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   starttime                9748 non-null   object \n",
      " 1   start station id         9748 non-null   int64  \n",
      " 2   start station latitude   9748 non-null   float64\n",
      " 3   start station longitude  9748 non-null   float64\n",
      " 4   ride_count               9748 non-null   int64  \n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 380.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read in one of the files to make sure it's exported correctly\n",
    "\n",
    "test = pd.read_csv('./processed/201409.csv')\n",
    "\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Oct 2016 through March 2017 with different column names\n",
    "\n",
    "# df_list3 = []\n",
    "\n",
    "month = 10\n",
    "year = 2016\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    if month > 12:\n",
    "        month = 1\n",
    "        year += 1\n",
    "    \n",
    "    if month >= 10:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}{month}-citibike-tripdata.csv\", names=standard_cols, skiprows=1)\n",
    "        df = pre_process(df)\n",
    "        df.to_csv(f\"./processed/{year}{month}.csv\")\n",
    "\n",
    "    else:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}0{month}-citibike-tripdata.csv\", names=standard_cols, skiprows=1)\n",
    "        df = pre_process(df)\n",
    "        df.to_csv(f\"./processed/{year}0{month}.csv\")\n",
    "    \n",
    "    month += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in April 2017 through Jan 2021\n",
    "\n",
    "# df_list4 = []\n",
    "\n",
    "month = 4\n",
    "year = 2017\n",
    "\n",
    "for i in range(46):\n",
    "    \n",
    "    if month > 12:\n",
    "        month = 1\n",
    "        year += 1\n",
    "    \n",
    "    if month >= 10:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}{month}-citibike-tripdata.csv\")\n",
    "        df = pre_process(df)\n",
    "        df.to_csv(f\"./processed/{year}{month}.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}0{month}-citibike-tripdata.csv\")\n",
    "        df = pre_process(df)\n",
    "        df.to_csv(f\"./processed/{year}0{month}.csv\")\n",
    "    \n",
    "    month += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in remainder through Oct 2021\n",
    "\n",
    "# df_list5 = []\n",
    "\n",
    "month = 2\n",
    "year = 2021\n",
    "\n",
    "for i in range(9):\n",
    "    \n",
    "    if month > 12:\n",
    "        month = 1\n",
    "        year += 1\n",
    "    \n",
    "    if month >= 10:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}{month}-citibike-tripdata.csv\", low_memory=False)\n",
    "        df = pre_process_2021(df)\n",
    "        df.to_csv(f\"./processed/{year}{month}.csv\")\n",
    "    else:\n",
    "        df = pd.read_csv(f\"./ridership_raw/{year}0{month}-citibike-tripdata.csv\", low_memory=False)\n",
    "        df = pre_process_2021(df)\n",
    "        df.to_csv(f\"./processed/{year}0{month}.csv\")\n",
    "    \n",
    "    month += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidate ridership files\n",
    "\n",
    "Read in the clean files, append them together, and rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in each CSV and append to the dataframe list\n",
    "\n",
    "df_list = []\n",
    "month = 6\n",
    "year = 2013\n",
    "\n",
    "for i in range(101):\n",
    "    \n",
    "    if month > 12:\n",
    "        month = 1\n",
    "        year += 1\n",
    "    \n",
    "    if month >= 10:\n",
    "        df = pd.read_csv(f\"./processed/{year}{month}.csv\", index_col=0)\n",
    "        df_list.append(df)\n",
    "\n",
    "    else:\n",
    "        df = pd.read_csv(f\"./processed/{year}0{month}.csv\", index_col=0)\n",
    "        df_list.append(df)\n",
    "    \n",
    "    month += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat list of dataframes together\n",
    "\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure index is a datetime variable\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df['year'] = df.index.map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "\n",
    "df = df.rename(columns={'start station id': 'station_id', 'start station latitude': 'lat', \n",
    "                                    'start station longitude': 'long'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>ride_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starttime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-01</th>\n",
       "      <td>72</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>40</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01</th>\n",
       "      <td>79</td>\n",
       "      <td>40.719116</td>\n",
       "      <td>-74.006667</td>\n",
       "      <td>61</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01</th>\n",
       "      <td>82</td>\n",
       "      <td>40.711174</td>\n",
       "      <td>-74.000165</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01</th>\n",
       "      <td>83</td>\n",
       "      <td>40.683826</td>\n",
       "      <td>-73.976323</td>\n",
       "      <td>32</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01</th>\n",
       "      <td>116</td>\n",
       "      <td>40.741776</td>\n",
       "      <td>-74.001497</td>\n",
       "      <td>53</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           station_id        lat       long  ride_count  year\n",
       "starttime                                                    \n",
       "2013-06-01         72  40.767272 -73.993929          40  2013\n",
       "2013-06-01         79  40.719116 -74.006667          61  2013\n",
       "2013-06-01         82  40.711174 -74.000165           6  2013\n",
       "2013-06-01         83  40.683826 -73.976323          32  2013\n",
       "2013-06-01        116  40.741776 -74.001497          53  2013"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sense check output\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2144526 entries, 2013-06-01 to 2021-10-31\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   station_id  object \n",
      " 1   lat         float64\n",
      " 2   long        float64\n",
      " 3   ride_count  int64  \n",
      " 4   year        int64  \n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 98.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Sense check output\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append neighborhood and borough information\n",
    "\n",
    "There are two approaches to adding neighborhood information:\n",
    "- geo_json file from NYC Open Data. Contains polygon objects containing coordinate information for each borough / neighborhood. Neighborhoods are matched based on Citibike station coordinate data. This is the approach that yields the best results (almost all stations match)\n",
    "- geopy reverse encoder: this library takes coordinates and returns information about the neighborhood. It works reasonably well, but produces an unacceptable number of nulls (~20% of stations). Code for this approach shown below, but ultimately note used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### geo_json approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3849 entries, 0 to 3848\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   station_id  3849 non-null   object \n",
      " 1   lat         3849 non-null   float64\n",
      " 2   long        3849 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 90.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Find unique set of stations\n",
    "\n",
    "df_unique = df.drop_duplicates(subset='station_id')\n",
    "\n",
    "df_stations = df_unique[['station_id', 'lat', 'long']].reset_index().drop('starttime', axis=1)\n",
    "\n",
    "df_stations.info()\n",
    "\n",
    "# There may be some \"duplicate stations\" given that the IDs may not be consistently named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in JSON map of NYC neighborhoods\n",
    "\n",
    "nycmap = json.load(open('./nyc_geo_data/2010 Neighborhood Tabulation Areas (NTAs).geojson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Feature',\n",
       " 'properties': {'ntacode': 'QN51',\n",
       "  'shape_area': '52488277.4492',\n",
       "  'county_fips': '081',\n",
       "  'ntaname': 'Murray Hill',\n",
       "  'shape_leng': '33266.9048559',\n",
       "  'boro_name': 'Queens',\n",
       "  'boro_code': '4'},\n",
       " 'geometry': {'type': 'MultiPolygon',\n",
       "  'coordinates': [[[[-73.80379022888246, 40.77561011179248],\n",
       "     [-73.80098974064948, 40.77538911645844],\n",
       "     [-73.79865192006208, 40.77520055898499],\n",
       "     [-73.79853009427278, 40.77519072888339],\n",
       "     [-73.7982329551194, 40.77484830546582],\n",
       "     [-73.7978540045323, 40.77441566944928],\n",
       "     [-73.79772190077279, 40.774272373809396],\n",
       "     [-73.79757522894504, 40.77413684204422],\n",
       "     [-73.79741530994487, 40.77401038228574],\n",
       "     [-73.79741522772021, 40.774010319151415],\n",
       "     [-73.79741514502729, 40.774010265062664],\n",
       "     [-73.79730005603771, 40.77393228605373],\n",
       "     [-73.79724339821908, 40.77389389663614],\n",
       "     [-73.79672685097921, 40.77360922870773],\n",
       "     [-73.79652490521445, 40.773503278471615],\n",
       "     [-73.79571707389985, 40.77306964277881],\n",
       "     [-73.7956570207727, 40.773036086714605],\n",
       "     [-73.79521550584715, 40.77267490720624],\n",
       "     [-73.79507190291262, 40.77254212458487],\n",
       "     [-73.79493636799305, 40.77240453038557],\n",
       "     [-73.79480546134086, 40.77225687477913],\n",
       "     [-73.79415923541369, 40.771516038270406],\n",
       "     [-73.79394905802262, 40.77126737493738],\n",
       "     [-73.79323711864232, 40.770467720809286],\n",
       "     [-73.79317944556045, 40.770403177727864],\n",
       "     [-73.79321182316966, 40.77033648909939],\n",
       "     [-73.79342227701162, 40.76859990751411],\n",
       "     [-73.7936127962241, 40.7672233575515],\n",
       "     [-73.79395914652879, 40.76469531992565],\n",
       "     [-73.79302551365764, 40.76462119218867],\n",
       "     [-73.79322483940079, 40.76314200768082],\n",
       "     [-73.7933454626059, 40.762295342852354],\n",
       "     [-73.79343673769405, 40.761596830829085],\n",
       "     [-73.79343800248607, 40.76151352662953],\n",
       "     [-73.79344299910191, 40.76118533750806],\n",
       "     [-73.79344033536174, 40.7608225267166],\n",
       "     [-73.79343991212555, 40.76076412796247],\n",
       "     [-73.79255338049309, 40.76084029433971],\n",
       "     [-73.79165466242237, 40.76091206344292],\n",
       "     [-73.79076004620481, 40.76098576942467],\n",
       "     [-73.79053451035577, 40.75937303821016],\n",
       "     [-73.79031516996666, 40.757823450590294],\n",
       "     [-73.79122151560277, 40.75779876580732],\n",
       "     [-73.79201171496791, 40.75778015034508],\n",
       "     [-73.79212059100126, 40.75777758234753],\n",
       "     [-73.79303015813379, 40.757756193775556],\n",
       "     [-73.79402473959107, 40.757735968956545],\n",
       "     [-73.79493246233996, 40.75779803007454],\n",
       "     [-73.7958043765478, 40.758091217004676],\n",
       "     [-73.79621926933264, 40.758241679534095],\n",
       "     [-73.7967046787129, 40.75841771177727],\n",
       "     [-73.79760259802707, 40.758744178543594],\n",
       "     [-73.79850160206708, 40.75907103553954],\n",
       "     [-73.79940088902902, 40.75939721905914],\n",
       "     [-73.80030039037474, 40.75970229914455],\n",
       "     [-73.80125017485658, 40.75982823730045],\n",
       "     [-73.80215291895342, 40.75998721801133],\n",
       "     [-73.80307328932783, 40.76012624811296],\n",
       "     [-73.80399971294425, 40.7602704875326],\n",
       "     [-73.80491668517477, 40.76044041190099],\n",
       "     [-73.80584005382896, 40.76061539065562],\n",
       "     [-73.8067604864991, 40.76078777314707],\n",
       "     [-73.80768023729503, 40.76095995883445],\n",
       "     [-73.80859484054315, 40.76113246182391],\n",
       "     [-73.80951372622066, 40.76129991102496],\n",
       "     [-73.81044348365442, 40.76137743901466],\n",
       "     [-73.81104963173331, 40.76141702058464],\n",
       "     [-73.8122677810063, 40.76113002164715],\n",
       "     [-73.81313229873767, 40.7608983491404],\n",
       "     [-73.81399882876018, 40.760665034320375],\n",
       "     [-73.81508732575519, 40.760371610605524],\n",
       "     [-73.81728821410807, 40.75977554707266],\n",
       "     [-73.82063593339372, 40.75887226784799],\n",
       "     [-73.82080684858931, 40.758941783316445],\n",
       "     [-73.82116405016134, 40.75968607609668],\n",
       "     [-73.82155809662825, 40.760534324499176],\n",
       "     [-73.82176735371574, 40.76097981376628],\n",
       "     [-73.8218107714836, 40.761072236774076],\n",
       "     [-73.82207359778963, 40.7616249540048],\n",
       "     [-73.82260198317297, 40.76275935649199],\n",
       "     [-73.8230251334364, 40.763666341209294],\n",
       "     [-73.82348245212701, 40.7646517923674],\n",
       "     [-73.82372658234787, 40.76582551589908],\n",
       "     [-73.82395032587073, 40.76688720215759],\n",
       "     [-73.82421202453423, 40.7681692279993],\n",
       "     [-73.82444330283612, 40.76928551407862],\n",
       "     [-73.82466909032317, 40.77040760780862],\n",
       "     [-73.82556485219212, 40.77028296009969],\n",
       "     [-73.82604927472877, 40.77021081449477],\n",
       "     [-73.82655841971643, 40.7701370835933],\n",
       "     [-73.82656578893099, 40.770641476230956],\n",
       "     [-73.82657511687418, 40.771630353012554],\n",
       "     [-73.8265748186573, 40.772345397962916],\n",
       "     [-73.82647720818895, 40.77311644279062],\n",
       "     [-73.82625348460336, 40.77452065960432],\n",
       "     [-73.82583089977442, 40.77591527158133],\n",
       "     [-73.8248680090884, 40.776542354845354],\n",
       "     [-73.82433101941247, 40.77674307080467],\n",
       "     [-73.82428360049255, 40.77698996098387],\n",
       "     [-73.82422147275781, 40.777235226984594],\n",
       "     [-73.82414480492373, 40.77747809322916],\n",
       "     [-73.82405384580922, 40.77771783066184],\n",
       "     [-73.82382109030323, 40.77836013815088],\n",
       "     [-73.82376244869411, 40.77850455199374],\n",
       "     [-73.82354681609371, 40.77903553756728],\n",
       "     [-73.82331286855239, 40.77957865983404],\n",
       "     [-73.82223999335496, 40.77949023704663],\n",
       "     [-73.82132278461545, 40.779409258891754],\n",
       "     [-73.82032141636081, 40.77933468076796],\n",
       "     [-73.81981042155475, 40.779296989188026],\n",
       "     [-73.81930985112398, 40.779260059856924],\n",
       "     [-73.8172814697289, 40.7791055131991],\n",
       "     [-73.81452997736083, 40.778888174879235],\n",
       "     [-73.81466305923627, 40.777904687696456],\n",
       "     [-73.81475883042387, 40.777203501143916],\n",
       "     [-73.81478821761245, 40.77699573898305],\n",
       "     [-73.81485850655602, 40.7764859231195],\n",
       "     [-73.81268626346109, 40.77631279409203],\n",
       "     [-73.80945252100933, 40.776058078746075],\n",
       "     [-73.80659228450709, 40.77583186152789],\n",
       "     [-73.80379022888246, 40.77561011179248]]]]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore structure of JSON\n",
    "# Each 'feature' has the coordinate map, borough name, and nta_name, which is what we're interested in\n",
    "\n",
    "nycmap['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreymarvel/opt/anaconda3/envs/citibike/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:118: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>point_coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>40.767272</td>\n",
       "      <td>-73.993929</td>\n",
       "      <td>POINT (-73.99392888 40.76727216)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>40.719116</td>\n",
       "      <td>-74.006667</td>\n",
       "      <td>POINT (-74.00666661 40.71911552)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>40.711174</td>\n",
       "      <td>-74.000165</td>\n",
       "      <td>POINT (-74.00016545 40.71117416)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83</td>\n",
       "      <td>40.683826</td>\n",
       "      <td>-73.976323</td>\n",
       "      <td>POINT (-73.97632328 40.68382604)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116</td>\n",
       "      <td>40.741776</td>\n",
       "      <td>-74.001497</td>\n",
       "      <td>POINT (-74.00149746 40.74177603)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id        lat       long                 point_coordinates\n",
       "0         72  40.767272 -73.993929  POINT (-73.99392888 40.76727216)\n",
       "1         79  40.719116 -74.006667  POINT (-74.00666661 40.71911552)\n",
       "2         82  40.711174 -74.000165  POINT (-74.00016545 40.71117416)\n",
       "3         83  40.683826 -73.976323  POINT (-73.97632328 40.68382604)\n",
       "4        116  40.741776 -74.001497  POINT (-74.00149746 40.74177603)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 'point' variable column out of the longitute and latitutde\n",
    "\n",
    "df_stations['point_coordinates'] = df_stations.apply(lambda row: Point(row['long'], row['lat']), axis=1)\n",
    "\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply neighborhood function to the coordinates\n",
    "\n",
    "df_stations['neighborhood'] = df_stations['point_coordinates'].apply(lambda x: neighborhood_json(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply borough function to the coordinates\n",
    "\n",
    "df_stations['borough'] = df_stations['point_coordinates'].apply(lambda x: borough_json(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Manhattan    1624\n",
       "Brooklyn     1091\n",
       "Bronx         650\n",
       "Queens        474\n",
       "Name: borough, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sense check the Borough output\n",
    "\n",
    "df_stations['borough'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Astoria                                       134\n",
       "Bushwick South                                130\n",
       "Hudson Yards-Chelsea-Flatiron-Union Square    114\n",
       "Midtown-Midtown South                         107\n",
       "Mott Haven-Port Morris                         94\n",
       "                                             ... \n",
       "park-cemetery-etc-Queens                        9\n",
       "Bay Ridge                                       8\n",
       "Kensington-Ocean Parkway                        7\n",
       "Flatbush                                        2\n",
       "Borough Park                                    2\n",
       "Name: neighborhood, Length: 82, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sense check the neighborhood output\n",
    "\n",
    "df_stations['neighborhood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map these stations back to the main dataframe based on station_id\n",
    "\n",
    "df = df.merge(df_stations, left_on='station_id', right_on='station_id', how='left').set_index(df.index)\n",
    "\n",
    "df.drop(labels=['lat_y', 'long_y', 'point_coordinates'], axis=1, inplace=True)\n",
    "\n",
    "df.rename(columns={'lat_x': 'lat', 'long_x': 'long'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2144526 entries, 2013-06-01 to 2021-10-31\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   station_id    object \n",
      " 1   lat           float64\n",
      " 2   long          float64\n",
      " 3   ride_count    int64  \n",
      " 4   year          int64  \n",
      " 5   neighborhood  object \n",
      " 6   borough       object \n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 130.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Sense check output\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read to CSV\n",
    "\n",
    "df.to_csv('./clean_data/clean_ridershare_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Notebook: Citibike EDA\n",
    "\n",
    "https://github.com/marvelje/citibike_ridership_project/blob/main/citibike_eda.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geopy approach\n",
    "\n",
    "- Note: commented out as it's not in use, but want to display an alternate approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify down to only lat and long\n",
    "\n",
    "# df_lat_long = df_stations[['lat', 'long']]\n",
    "\n",
    "# Convert to geopandas object\n",
    "\n",
    "# gdf_citibike = gpd.GeoDataFrame(df_lat_long, geometry=gpd.points_from_xy(df_lat_long.long, df_lat_long.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample lat /long\n",
    "\n",
    "# geolocator = Nominatim(user_agent='citi_bike_share_analysis')\n",
    "\n",
    "# sample_lat_long = df_stations.loc[0,['lat', 'long']]\n",
    "# lat = sample_lat_long[0]\n",
    "# long = sample_lat_long[1]\n",
    "# combined = str(lat) + ', ' + str(long)\n",
    "# location = geolocator.reverse(combined)\n",
    "# location.raw['address']['neighbourhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply geolocator to every station in the dataset\n",
    "\n",
    "# df_stations['neighborhood'] = df_stations.apply(lambda row: get_neighborhood(row['lat'], row['long']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display null neighborhoods from this approach\n",
    "\n",
    "# null_neighborhoods = df_stations[df_stations['neighborhood'].isna()]\n",
    "\n",
    "# null_neighborhoods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citibike",
   "language": "python",
   "name": "citibike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
